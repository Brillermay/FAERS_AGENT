import os
import pandas as pd
import numpy as np
from collections import Counter
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
import pickle
import json

class ReactionDataPreparator:
    def __init__(
        self, 
        csv_path, 
        max_samples=10000,
        high_freq_min=75,
        med_freq_min=10,
        low_freq_min=5,
        high_ratio=0.6,
        med_ratio=0.9,
        low_ratio=0.3,
        exclude_non_physiological=False,  # ðŸ”¥ æ·»åŠ è¿™ä¸ªå‚æ•°
        test_size=0.2,  # ðŸ”¥ æ·»åŠ è¿™ä¸ªå‚æ•°
        random_state=42  # ðŸ”¥ æ·»åŠ è¿™ä¸ªå‚æ•°
    ):
        """
        Args:
            csv_path: CSVæ–‡ä»¶è·¯å¾„
            exclude_non_physiological: æ˜¯å¦æŽ’é™¤éžç”Ÿç†ååº”
            test_size: éªŒè¯é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
        """
        self.csv_path = csv_path
        self.max_samples = max_samples
        self.high_freq_min = high_freq_min
        self.med_freq_min = med_freq_min
        self.low_freq_min = low_freq_min
        self.high_ratio = high_ratio
        self.med_ratio = med_ratio
        self.low_ratio = low_ratio
        self.exclude_non_physiological = exclude_non_physiological  # ðŸ”¥ æ·»åŠ 
        self.test_size = test_size  # ðŸ”¥ æ·»åŠ 
        self.random_state = random_state  # ðŸ”¥ æ·»åŠ 
        
        # éžç”Ÿç†ååº”æŽ’é™¤åˆ—è¡¨
        self.non_physiological_reactions = {
            "off label use",
            "drug ineffective", 
            "product dose omission issue",
            "drug interaction",
            "product dose omission",
            "therapeutic use unknown",
            "product used for unknown indication"
        }
        
    def load_and_clean_data(self):
        """åŠ è½½å¹¶æ¸…ç†æ•°æ®"""
        print("ðŸ“ åŠ è½½æ•°æ®...")
        df = pd.read_csv(self.csv_path)
        print(f"åŽŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        
        # è§£æžlabels_list
        def parse_labels(labels_str):
            try:
                if isinstance(labels_str, str):
                    labels = eval(labels_str)
                else:
                    labels = labels_str if labels_str else []
                return [l.strip().lower() for l in labels if l and str(l).strip()]
            except:
                return []
        
        df['labels_parsed'] = df['labels_list'].apply(parse_labels)
        
        # è¿‡æ»¤æŽ‰æ²¡æœ‰æ ‡ç­¾çš„æ ·æœ¬
        df = df[df['labels_parsed'].apply(len) > 0].reset_index(drop=True)
        print(f"æœ‰æ ‡ç­¾çš„è®°å½•: {len(df)} æ¡")
        
        if self.exclude_non_physiological:
            print("ðŸ§¹ è¿‡æ»¤éžç”Ÿç†ååº”...")
            def filter_physiological(labels):
                return [l for l in labels if l not in self.non_physiological_reactions]
            
            df['labels_filtered'] = df['labels_parsed'].apply(filter_physiological)
            df = df[df['labels_filtered'].apply(len) > 0].reset_index(drop=True)
            print(f"è¿‡æ»¤åŽè®°å½•: {len(df)} æ¡")
            df['labels_final'] = df['labels_filtered']
        else:
            df['labels_final'] = df['labels_parsed']
        
        return df
    
    def get_reaction_stats(self, df):
        """èŽ·å–ååº”ç»Ÿè®¡ä¿¡æ¯"""
        all_reactions = []
        for labels in df['labels_final']:
            all_reactions.extend(labels)
        
        reaction_counts = Counter(all_reactions)
        total_reactions = len(reaction_counts)
        total_occurrences = sum(reaction_counts.values())
        
        print(f"ðŸ“Š ååº”ç»Ÿè®¡:")
        print(f"  - å”¯ä¸€ååº”æ•°: {total_reactions}")
        print(f"  - æ€»å‡ºçŽ°æ¬¡æ•°: {total_occurrences}")
        print(f"  - å¹³å‡æ¯ä¾‹ååº”æ•°: {total_occurrences/len(df):.2f}")
        print(f"  - åªå‡ºçŽ°1æ¬¡çš„ååº”: {sum(1 for c in reaction_counts.values() if c == 1)} ({sum(1 for c in reaction_counts.values() if c == 1)/total_reactions*100:.1f}%)")
        
        return reaction_counts
    
    def strategy_a_layered_sampling(self, reaction_counts, head_k=200, tail_k=300):
        """æ–¹æ¡ˆA: åˆ†å±‚é‡‡æ ·"""
        print(f"ðŸŽ¯ æ–¹æ¡ˆA: Head-{head_k} + Tail-{tail_k} é‡‡æ ·")
        
        # æŒ‰é¢‘æ¬¡æŽ’åº
        sorted_reactions = reaction_counts.most_common()
        
        # Head: æœ€å¸¸è§çš„reactions
        head_reactions = [r for r, c in sorted_reactions[:head_k]]
        
        # Tail: ä»Žé•¿å°¾ä¸­éšæœºé‡‡æ ·ï¼ˆæŽ’é™¤headä¸­å·²æœ‰çš„ï¼‰
        tail_candidates = [r for r, c in sorted_reactions[head_k:] if c >= 2]  # è‡³å°‘å‡ºçŽ°2æ¬¡
        
        if len(tail_candidates) >= tail_k:
            np.random.seed(self.random_state)
            tail_reactions = list(np.random.choice(tail_candidates, tail_k, replace=False))
        else:
            tail_reactions = tail_candidates
            print(f"âš ï¸  é•¿å°¾å€™é€‰ä¸è¶³ï¼Œå®žé™…é€‰æ‹©: {len(tail_reactions)}")
        
        selected_reactions = head_reactions + tail_reactions
        
        print(f"âœ… æ–¹æ¡ˆAé€‰æ‹©çš„ååº”æ•°: {len(selected_reactions)}")
        print(f"  - Head: {len(head_reactions)} (é¢‘æ¬¡è¦†ç›–: {sum(reaction_counts[r] for r in head_reactions)/sum(reaction_counts.values())*100:.1f}%)")
        print(f"  - Tail: {len(tail_reactions)}")
        
        return selected_reactions
    
    def strategy_b_frequency_stratified(self, reaction_counts, 
                                      high_freq_min=50, med_freq_min=10, low_freq_min=2,
                                      high_ratio=0.4, med_ratio=0.3, low_ratio=0.3, 
                                      total_target=500):
        """æ–¹æ¡ˆB: é¢‘æ¬¡åˆ†å±‚"""
        print(f"ðŸŽ¯ æ–¹æ¡ˆB: é¢‘æ¬¡åˆ†å±‚é‡‡æ · (ç›®æ ‡: {total_target})")
        
        # æŒ‰é¢‘æ¬¡åˆ†å±‚
        high_freq = [(r, c) for r, c in reaction_counts.items() if c >= high_freq_min]
        med_freq = [(r, c) for r, c in reaction_counts.items() if med_freq_min <= c < high_freq_min]  
        low_freq = [(r, c) for r, c in reaction_counts.items() if low_freq_min <= c < med_freq_min]
        
        print(f"  - é«˜é¢‘ (â‰¥{high_freq_min}): {len(high_freq)}")
        print(f"  - ä¸­é¢‘ ({med_freq_min}-{high_freq_min-1}): {len(med_freq)}")
        print(f"  - ä½Žé¢‘ ({low_freq_min}-{med_freq_min-1}): {len(low_freq)}")
        
        # æŒ‰æ¯”ä¾‹é‡‡æ ·
        high_target = int(total_target * high_ratio)
        med_target = int(total_target * med_ratio)
        low_target = total_target - high_target - med_target
        
        np.random.seed(self.random_state)
        
        # é‡‡æ · - é«˜é¢‘æŒ‰é¢‘æ¬¡æŽ’åºå–å‰Nä¸ª
        high_freq_sorted = sorted(high_freq, key=lambda x: -x[1])
        high_selected = [r for r, c in high_freq_sorted[:high_target]]
        
        # ä¸­é¢‘éšæœºé‡‡æ ·
        if len(med_freq) >= med_target:
            med_reactions = [r for r, c in med_freq]
            selected_indices = np.random.choice(len(med_reactions), med_target, replace=False)
            med_selected = [med_reactions[i] for i in selected_indices]
        else:
            med_selected = [r for r, c in med_freq]
            
        # ä½Žé¢‘éšæœºé‡‡æ ·
        if len(low_freq) >= low_target:
            low_reactions = [r for r, c in low_freq]
            selected_indices = np.random.choice(len(low_reactions), low_target, replace=False)
            low_selected = [low_reactions[i] for i in selected_indices]
        else:
            low_selected = [r for r, c in low_freq]
        
        selected_reactions = high_selected + med_selected + low_selected
        
        print(f"âœ… æ–¹æ¡ˆBé€‰æ‹©çš„ååº”æ•°: {len(selected_reactions)}")
        print(f"  - é«˜é¢‘: {len(high_selected)}")
        print(f"  - ä¸­é¢‘: {len(med_selected)}")
        print(f"  - ä½Žé¢‘: {len(low_selected)}")
        
        return selected_reactions
    
    def prepare_training_data(self, df, selected_reactions, 
                            prioritize_rare=True, max_samples=3000):
        """å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼šè¿”å›ž label indices è€Œéžç¨ å¯†çŸ©é˜µï¼‰"""
        print(f"ðŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆç¨€ç–æ ‡ç­¾ï¼‰...")
        
        # è¿‡æ»¤æ ·æœ¬ï¼šåªä¿ç•™åŒ…å«é€‰ä¸­reactionsçš„samples
        def has_selected_reaction(labels):
            return any(l in selected_reactions for l in labels)
        
        df_filtered = df[df['labels_final'].apply(has_selected_reaction)].copy()
        print(f"åŒ…å«ç›®æ ‡ååº”çš„æ ·æœ¬: {len(df_filtered)}")
        
        # é‡æ–°è¿‡æ»¤æ ‡ç­¾
        def filter_labels(labels):
            return [l for l in labels if l in selected_reactions]
        
        df_filtered['labels_final_filtered'] = df_filtered['labels_final'].apply(filter_labels)
        df_filtered = df_filtered[df_filtered['labels_final_filtered'].apply(len) > 0]
        
        # ä¼˜å…ˆä¿ç•™åŒ…å«ç¨€æœ‰ååº”çš„æ ·æœ¬
        if prioritize_rare and len(df_filtered) > max_samples:
            print(f"ðŸŽ² ä¼˜å…ˆé‡‡æ ·åŒ…å«ç¨€æœ‰ååº”çš„æ ·æœ¬...")
            reaction_counts_selected = Counter()
            for labels in df_filtered['labels_final_filtered']:
                reaction_counts_selected.update(labels)
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç¨€æœ‰åº¦åˆ†æ•°ï¼ˆåŒ…å«çš„reactioné¢‘æ¬¡å€’æ•°ä¹‹å’Œï¼‰
            def rarity_score(labels):
                return sum(1.0 / reaction_counts_selected[l] for l in labels)
            
            df_filtered['rarity_score'] = df_filtered['labels_final_filtered'].apply(rarity_score)
            
            # æŒ‰ç¨€æœ‰åº¦åˆ†å±‚é‡‡æ ·
            df_sorted = df_filtered.sort_values('rarity_score', ascending=False)
            
            # å–top 70%é«˜ç¨€æœ‰åº¦ + 30%éšæœº
            high_rare_n = int(max_samples * 0.7)
            random_n = max_samples - high_rare_n
            
            high_rare_samples = df_sorted.head(high_rare_n)
            remaining_samples = df_sorted.iloc[high_rare_n:]
            
            if len(remaining_samples) >= random_n:
                random_samples = remaining_samples.sample(n=random_n, random_state=self.random_state)
            else:
                random_samples = remaining_samples
            
            df_final = pd.concat([high_rare_samples, random_samples]).drop(columns=['rarity_score'])
        else:
            df_final = df_filtered.sample(n=min(len(df_filtered), max_samples), 
                                        random_state=self.random_state)
        
        print(f"æœ€ç»ˆè®­ç»ƒæ ·æœ¬æ•°: {len(df_final)}")
        
        # Fit MultiLabelBinarizer but ä¸ transform ä¸ºç¨ å¯†çŸ©é˜µ
        mlb = MultiLabelBinarizer()
        mlb.fit(df_final['labels_final_filtered'])
        label_to_idx = {label: idx for idx, label in enumerate(mlb.classes_)}
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬æž„é€  label indicesï¼ˆç¨€ç–å­˜å‚¨ï¼‰
        df_final['label_indices'] = df_final['labels_final_filtered'].apply(
            lambda ls: [label_to_idx[l] for l in ls]
        )
        
        print(f"æ ‡ç­¾ç©ºé—´ç»´åº¦: {len(mlb.classes_)}")
        # è®¡ç®—å¹³å‡æ¯æ ·æœ¬æ ‡ç­¾æ•°
        avg_labels_per_sample = df_final['label_indices'].apply(len).mean()
        print(f"å¹³å‡æ¯æ ·æœ¬æ ‡ç­¾æ•°: {avg_labels_per_sample:.2f}")
        
        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›† (æŒ‰primaryidåˆ†å‰²ï¼Œé¿å…æ³„éœ²)
        unique_ids = df_final['primaryid'].unique()
        train_ids, val_ids = train_test_split(unique_ids, 
                                            test_size=self.test_size, 
                                            random_state=self.random_state)
        
        train_mask = df_final['primaryid'].isin(train_ids)
        val_mask = df_final['primaryid'].isin(val_ids)
        
        train_data = {
            'prompts': df_final[train_mask]['prompt'].tolist(),
            'labels': df_final[train_mask]['label_indices'].tolist(),
            'primaryids': df_final[train_mask]['primaryid'].tolist()
        }
        
        val_data = {
            'prompts': df_final[val_mask]['prompt'].tolist(),
            'labels': df_final[val_mask]['label_indices'].tolist(),
            'primaryids': df_final[val_mask]['primaryid'].tolist()
        }
        
        print(f"è®­ç»ƒé›†: {len(train_data['prompts'])} æ ·æœ¬")
        print(f"éªŒè¯é›†: {len(val_data['prompts'])} æ ·æœ¬")
        
        return train_data, val_data, mlb, selected_reactions

    def select_reactions(self):
        """æŒ‰æ–°ç­–ç•¥é€‰æ‹©ååº”"""
        import random
        random.seed(42)
        
        # æŒ‰é¢‘çŽ‡åˆ†ç»„
        high_freq = [r for r, c in self.reaction_counts.items() if c >= self.high_freq_min]
        med_freq = [r for r, c in self.reaction_counts.items() if self.med_freq_min <= c < self.high_freq_min]
        low_freq = [r for r, c in self.reaction_counts.items() if self.low_freq_min <= c < self.med_freq_min]
        
        print(f"\nðŸ“Š é¢‘çŽ‡åˆ†å¸ƒ:")
        print(f"  é«˜é¢‘ (>={self.high_freq_min}): {len(high_freq)}")
        print(f"  ä¸­é¢‘ ({self.med_freq_min}-{self.high_freq_min-1}): {len(med_freq)}")
        print(f"  ä½Žé¢‘ ({self.low_freq_min}-{self.med_freq_min-1}): {len(low_freq)}")
        
        # æŒ‰æ¯”ä¾‹é‡‡æ ·
        num_high = int(len(high_freq) * self.high_ratio)
        num_med = int(len(med_freq) * self.med_ratio)
        num_low = int(len(low_freq) * self.low_ratio)
        
        selected_high = random.sample(high_freq, num_high) if num_high > 0 else []
        selected_med = random.sample(med_freq, num_med) if num_med > 0 else []
        selected_low = random.sample(low_freq, num_low) if num_low > 0 else []
        
        self.selected_reactions = selected_high + selected_med + selected_low
        
        print(f"\nâœ… é€‰æ‹©ç»“æžœ:")
        print(f"  é«˜é¢‘: {len(selected_high)} ({self.high_ratio*100:.0f}%)")
        print(f"  ä¸­é¢‘: {len(selected_med)} ({self.med_ratio*100:.0f}%)")
        print(f"  ä½Žé¢‘: {len(selected_low)} ({self.low_ratio*100:.0f}%)")
        print(f"  æ€»è®¡: {len(self.selected_reactions)}")


def prepare_data_strategy_a(csv_path, max_samples=3000, head_k=200, tail_k=300, **kwargs):
    """æ–¹æ¡ˆAæ•°æ®å‡†å¤‡çš„ä¾¿æ·å‡½æ•°"""
    # ä¿®å¤ï¼šç§»é™¤max_samplesä»Ž__init__å‚æ•°ä¸­ï¼Œåœ¨prepare_training_dataä¸­ä½¿ç”¨
    preparator = ReactionDataPreparator(csv_path, **kwargs)
    df = preparator.load_and_clean_data()
    reaction_counts = preparator.get_reaction_stats(df)
    selected_reactions = preparator.strategy_a_layered_sampling(reaction_counts, head_k=head_k, tail_k=tail_k)
    return preparator.prepare_training_data(df, selected_reactions, max_samples=max_samples)


def prepare_data_strategy_b(
    csv_path,
    max_samples=10000,
    high_freq_min=75,
    med_freq_min=10,
    low_freq_min=5,
    high_ratio=0.6,
    med_ratio=0.9,
    low_ratio=0.3,
    exclude_non_physiological=False,  # ðŸ”¥ æ·»åŠ 
    test_size=0.2,  # ðŸ”¥ æ·»åŠ 
    random_state=42  # ðŸ”¥ æ·»åŠ 
):
    """ç­–ç•¥Bï¼šæŒ‰æ¯”ä¾‹ä»Žå„é¢‘æ®µé‡‡æ ·"""
    
    preparator = ReactionDataPreparator(
        csv_path=csv_path,
        max_samples=max_samples,
        high_freq_min=high_freq_min,
        med_freq_min=med_freq_min,
        low_freq_min=low_freq_min,
        high_ratio=high_ratio,
        med_ratio=med_ratio,
        low_ratio=low_ratio,
        exclude_non_physiological=exclude_non_physiological,  # ðŸ”¥ ä¼ é€’
        test_size=test_size,  # ðŸ”¥ ä¼ é€’
        random_state=random_state  # ðŸ”¥ ä¼ é€’
    )
    
    df = preparator.load_and_clean_data()
    reaction_counts = preparator.get_reaction_stats(df)
    
    # æŒ‰é¢‘çŽ‡åˆ†ç»„
    high_freq_labels = [label for label, count in reaction_counts.items() if count >= high_freq_min]
    med_freq_labels = [label for label, count in reaction_counts.items() if med_freq_min <= count < high_freq_min]
    low_freq_labels = [label for label, count in reaction_counts.items() if low_freq_min <= count < med_freq_min]
    
    print(f"\nðŸ“Š æ ‡ç­¾é¢‘çŽ‡åˆ†å¸ƒ:")
    print(f"  é«˜é¢‘æ ‡ç­¾ (>={high_freq_min}): {len(high_freq_labels)} ä¸ª")
    print(f"  ä¸­é¢‘æ ‡ç­¾ ({med_freq_min}-{high_freq_min-1}): {len(med_freq_labels)} ä¸ª")
    print(f"  ä½Žé¢‘æ ‡ç­¾ ({low_freq_min}-{med_freq_min-1}): {len(low_freq_labels)} ä¸ª")
    
    # æŒ‰æ¯”ä¾‹é‡‡æ ·
    num_high = int(len(high_freq_labels) * high_ratio)
    num_med = int(len(med_freq_labels) * med_ratio)
    num_low = int(len(low_freq_labels) * low_ratio)
    
    import random
    random.seed(random_state)
    
    selected_high = random.sample(high_freq_labels, num_high) if num_high > 0 and len(high_freq_labels) >= num_high else high_freq_labels
    selected_med = random.sample(med_freq_labels, num_med) if num_med > 0 and len(med_freq_labels) >= num_med else med_freq_labels
    selected_low = random.sample(low_freq_labels, num_low) if num_low > 0 and len(low_freq_labels) >= num_low else low_freq_labels
    
    selected_reactions = selected_high + selected_med + selected_low
    
    print(f"\nâœ… é€‰æ‹©çš„æ ‡ç­¾:")
    print(f"  é«˜é¢‘: {len(selected_high)} / {len(high_freq_labels)} ({high_ratio*100:.0f}%)")
    print(f"  ä¸­é¢‘: {len(selected_med)} / {len(med_freq_labels)} ({med_ratio*100:.0f}%)")
    print(f"  ä½Žé¢‘: {len(selected_low)} / {len(low_freq_labels)} ({low_ratio*100:.0f}%)")
    print(f"  æ€»è®¡: {len(selected_reactions)} ä¸ªæ ‡ç­¾")
    
    return preparator.prepare_training_data(df, selected_reactions, max_samples=max_samples)


if __name__ == "__main__":
    # æµ‹è¯•
    csv_path = "../outputs/prompts_sample_10000_coarse_coarse_v2.csv"  # ä¿®æ­£è·¯å¾„
    
    print("=== æ–¹æ¡ˆAæµ‹è¯• ===")
    train_a, val_a, mlb_a, reactions_a = prepare_data_strategy_a(csv_path)
    
    print("\n=== æ–¹æ¡ˆBæµ‹è¯• ===") 
    train_b, val_b, mlb_b, reactions_b = prepare_data_strategy_b(csv_path)